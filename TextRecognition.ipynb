{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextRecognition.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mojo46/Machine-Learning-noob/blob/master/TextRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YxZXSmJeqaD",
        "colab_type": "code",
        "outputId": "334b63f8-f1e9-4d76-89d5-cdfcc2f532f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "!git clone https://github.com/clovaai/deep-text-recognition-benchmark.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-text-recognition-benchmark'...\n",
            "remote: Enumerating objects: 394, done.\u001b[K\n",
            "remote: Total 394 (delta 0), reused 0 (delta 0), pack-reused 394\u001b[K\n",
            "Receiving objects: 100% (394/394), 2.99 MiB | 2.38 MiB/s, done.\n",
            "Resolving deltas: 100% (239/239), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kzg2SYOfX05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAhdy908vO7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "def unzip_a_zip(file_path, dest_dir=cwd):\n",
        "  from zipfile import ZipFile\n",
        "  with ZipFile(file_path, 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall(dest_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf6ILWMxvxrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unzip_a_zip(\"/content/clear_alpha_num_output.zip\") # enter zip file path and destination path if nessary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVNKr5eS4IoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip  '/content/drive/My Drive/DataSet/outputNP3.zip' -d '/content'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B8hN5SdpRwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path='/content/drive/My Drive/pretrained_model/TPS-ResNet-BiLSTM-Attn.pth'\n",
        "\n",
        "image_folder = '/content/output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqPosoEJDj5Q",
        "colab_type": "code",
        "outputId": "375334a2-6d26-49ff-9b6e-4378ebdae93c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/pretrained_model/TPS-ResNet-BiLSTM-Attn.pth'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/drive/My Drive/pretrained_model/TPS-ResNet-BiLSTM-Attn.pth'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEG76NNtDQqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#write dataframe to a csv file\n",
        "def write_to_csv(file_name,df):\n",
        "  import csv\n",
        "  with open(f'{df}', 'w') as csvfile:\n",
        "      writer=csv.writer(csvfile, delimiter=',')\n",
        "      writer.writerows(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd9saZHMpbot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python '/content/deep-text-recognition-benchmark/demo.py' \\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n",
        "--image_folder '/content/output' \\\n",
        "--saved_model '/content/drive/My Drive/pretrained_model/TPS-ResNet-BiLSTM-Attn.pth'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSUJf3PFGwle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /content/deep-text-recognition-benchmark/demo.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmDdqdSfIAIS",
        "colab_type": "code",
        "outputId": "f701b8dd-fd32-4bf9-c384-721e3bed2589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%%writefile /content/deep-text-recognition-benchmark/demo.py\n",
        "\n",
        "import string\n",
        "import argparse\n",
        "import csv\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from utils import CTCLabelConverter, AttnLabelConverter\n",
        "from dataset import RawDataset, AlignCollate\n",
        "from model import Model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "def demo(opt):\n",
        "    \"\"\" model configuration \"\"\"\n",
        "    if 'CTC' in opt.Prediction:\n",
        "        converter = CTCLabelConverter(opt.character)\n",
        "    else:\n",
        "        converter = AttnLabelConverter(opt.character)\n",
        "    opt.num_class = len(converter.character)\n",
        "\n",
        "    if opt.rgb:\n",
        "        opt.input_channel = 3\n",
        "    model = Model(opt)\n",
        "    print('model input parameters', opt.imgH, opt.imgW, opt.num_fiducial, opt.input_channel, opt.output_channel,\n",
        "          opt.hidden_size, opt.num_class, opt.batch_max_length, opt.Transformation, opt.FeatureExtraction,\n",
        "          opt.SequenceModeling, opt.Prediction)\n",
        "    model = torch.nn.DataParallel(model).to(device)\n",
        "\n",
        "    # load model\n",
        "    print('loading pretrained model from %s' % opt.saved_model)\n",
        "    model.load_state_dict(torch.load(opt.saved_model, map_location=device))\n",
        "\n",
        "    # prepare data. two demo images from https://github.com/bgshih/crnn#run-demo\n",
        "    AlignCollate_demo = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD)\n",
        "    demo_data = RawDataset(root=opt.image_folder, opt=opt)  # use RawDataset\n",
        "    demo_loader = torch.utils.data.DataLoader(\n",
        "        demo_data, batch_size=opt.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=int(opt.workers),\n",
        "        collate_fn=AlignCollate_demo, pin_memory=True)\n",
        "\n",
        "    # predict\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        with open('results.csv', 'w') as csvfile:\n",
        "          writer=csv.writer(csvfile, delimiter=',')\n",
        "\n",
        "          for image_tensors, image_path_list in demo_loader:\n",
        "              batch_size = image_tensors.size(0)\n",
        "              image = image_tensors.to(device)\n",
        "              # For max length prediction\n",
        "              length_for_pred = torch.IntTensor([opt.batch_max_length] * batch_size).to(device)\n",
        "              text_for_pred = torch.LongTensor(batch_size, opt.batch_max_length + 1).fill_(0).to(device)\n",
        "\n",
        "              if 'CTC' in opt.Prediction:\n",
        "                  preds = model(image, text_for_pred).log_softmax(2)\n",
        "\n",
        "                  # Select max probabilty (greedy decoding) then decode index to character\n",
        "                  preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
        "                  _, preds_index = preds.max(2)\n",
        "                  preds_index = preds_index.view(-1)\n",
        "                  preds_str = converter.decode(preds_index.data, preds_size.data)\n",
        "\n",
        "              else:\n",
        "                  preds = model(image, text_for_pred, is_train=False)\n",
        "\n",
        "                  # select max probabilty (greedy decoding) then decode index to character\n",
        "                  _, preds_index = preds.max(2)\n",
        "                  preds_str = converter.decode(preds_index, length_for_pred)\n",
        "\n",
        "              print('-' * 80)\n",
        "              print(f'{\"image_path\":25s}\\t{\"predicted_labels\":25s}\\tconfidence score')\n",
        "              print('-' * 80)\n",
        "              preds_prob = F.softmax(preds, dim=2)\n",
        "              preds_max_prob, _ = preds_prob.max(dim=2)\n",
        "              print('image',image_path_list,'predi   ',preds_str)\n",
        "\n",
        "              for img_name, pred, pred_max_prob in zip(image_path_list, preds_str, preds_max_prob):\n",
        "                  if 'Attn' in opt.Prediction:\n",
        "                      pred_EOS = pred.find('[s]')\n",
        "                      pred = pred[:pred_EOS]  # prune after \"end of sentence\" token ([s])\n",
        "                      pred_max_prob = pred_max_prob[:pred_EOS]\n",
        "\n",
        "                  # calculate confidence score (= multiply of pred_max_prob)\n",
        "                  confidence_score = pred_max_prob.cumprod(dim=0)[-1]\n",
        "\n",
        "                  # print(f'{img_name}\\t{pred}\\t{confidence_score:0.4f}')\n",
        "                  # print(f'{img_name:25s}\\t{pred:25s}\\t{confidence_score:0.4f}')\n",
        "                  print(f'{img_name}\\t{pred}\\t{confidence_score}')\n",
        "                  confi = f'{confidence_score:0.4f}'\n",
        "                  results1 = [(img_name,pred,confi)]\n",
        "                  writer.writerows(results1)\n",
        "                    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--image_folder', required=True, help='path to image_folder which contains text images')\n",
        "    parser.add_argument('--workers', type=int, help='number of data loading workers', default=4)\n",
        "    parser.add_argument('--batch_size', type=int, default=192, help='input batch size')\n",
        "    parser.add_argument('--saved_model', required=True, help=\"path to saved_model to evaluation\")\n",
        "    \"\"\" Data processing \"\"\"\n",
        "    parser.add_argument('--batch_max_length', type=int, default=25, help='maximum-label-length')\n",
        "    parser.add_argument('--imgH', type=int, default=32, help='the height of the input image')\n",
        "    parser.add_argument('--imgW', type=int, default=100, help='the width of the input image')\n",
        "    parser.add_argument('--rgb', action='store_true', help='use rgb input')\n",
        "    parser.add_argument('--character', type=str, default='0123456789abcdefghijklmnopqrstuvwxyz', help='character label')\n",
        "    parser.add_argument('--sensitive', action='store_true', help='for sensitive character mode')\n",
        "    parser.add_argument('--PAD', action='store_true', help='whether to keep ratio then pad for image resize')\n",
        "    \"\"\" Model Architecture \"\"\"\n",
        "    parser.add_argument('--Transformation', type=str, required=True, help='Transformation stage. None|TPS')\n",
        "    parser.add_argument('--FeatureExtraction', type=str, required=True, help='FeatureExtraction stage. VGG|RCNN|ResNet')\n",
        "    parser.add_argument('--SequenceModeling', type=str, required=True, help='SequenceModeling stage. None|BiLSTM')\n",
        "    parser.add_argument('--Prediction', type=str, required=True, help='Prediction stage. CTC|Attn')\n",
        "    parser.add_argument('--num_fiducial', type=int, default=20, help='number of fiducial points of TPS-STN')\n",
        "    parser.add_argument('--input_channel', type=int, default=1, help='the number of input channel of Feature extractor')\n",
        "    parser.add_argument('--output_channel', type=int, default=512,\n",
        "                        help='the number of output channel of Feature extractor')\n",
        "    parser.add_argument('--hidden_size', type=int, default=256, help='the size of the LSTM hidden state')\n",
        "\n",
        "    opt = parser.parse_args()\n",
        "\n",
        "    \"\"\" vocab / character number configuration \"\"\"\n",
        "    if opt.sensitive:\n",
        "        opt.character = string.printable[:-6]  # same with ASTER setting (use 94 char).\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "    cudnn.deterministic = True\n",
        "    opt.num_gpu = torch.cuda.device_count()\n",
        "\n",
        "    demo(opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/deep-text-recognition-benchmark/demo.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6ydVEu8DXeH",
        "colab_type": "text"
      },
      "source": [
        "Commands to Edit code in colabs itself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPsD5g3II1fn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pycat /content/deep-text-recognition-benchmark/demo.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYupgUjeJAOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm /content/deep-text-recognition-benchmark/demo.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlz1XnTzJaNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile /content/deep-text-recognition-benchmark/demo.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBMECoHxh-d_",
        "colab_type": "text"
      },
      "source": [
        "Filter data by catagory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXZVUkOg_0-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXX9uxBBFPR9",
        "colab_type": "code",
        "outputId": "df6365b0-645a-4e2c-f709-c3ce0f28824d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "#Import csv to Dataframe and convert class column lower case to upper\n",
        "resultsss =  pd.read_csv(\"/content/results.csv\",header=None)\n",
        "resultsss[1] = resultsss[1].apply(lambda x: x.upper())\n",
        "resultsss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/output/0.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.9995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/output/1.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0.3818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/output/2.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/output/3.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.9995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/output/4.jpg</td>\n",
              "      <td>A</td>\n",
              "      <td>0.9998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9922</th>\n",
              "      <td>/content/output/9922.jpg</td>\n",
              "      <td>6</td>\n",
              "      <td>0.9995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9923</th>\n",
              "      <td>/content/output/9923.jpg</td>\n",
              "      <td>V</td>\n",
              "      <td>0.9717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9924</th>\n",
              "      <td>/content/output/9924.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9925</th>\n",
              "      <td>/content/output/9925.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>0.9998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9926</th>\n",
              "      <td>/content/output/9926.jpg</td>\n",
              "      <td>I</td>\n",
              "      <td>0.3966</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9927 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             0  1       2\n",
              "0        /content/output/0.jpg  2  0.9995\n",
              "1        /content/output/1.jpg  0  0.3818\n",
              "2        /content/output/2.jpg  1  0.6789\n",
              "3        /content/output/3.jpg  2  0.9995\n",
              "4        /content/output/4.jpg  A  0.9998\n",
              "...                        ... ..     ...\n",
              "9922  /content/output/9922.jpg  6  0.9995\n",
              "9923  /content/output/9923.jpg  V  0.9717\n",
              "9924  /content/output/9924.jpg  1  0.9969\n",
              "9925  /content/output/9925.jpg  4  0.9998\n",
              "9926  /content/output/9926.jpg  I  0.3966\n",
              "\n",
              "[9927 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le3lPLEzDuYN",
        "colab_type": "text"
      },
      "source": [
        "Function to generate alphabets and digits list of char"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPdVm50I-Kq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to generate alphabets and digits list of charectors\n",
        "def alpha_num_list():\n",
        "  alphabets = [] \n",
        "  alpha = 'A'\n",
        "  for i in range(0, 26): \n",
        "      alphabets.append(alpha) \n",
        "      alpha = chr(ord(alpha) + 1)\n",
        "  numbers =  list(range(0,10))\n",
        "  AplhaNum_list = numbers + alphabets\n",
        "\n",
        "  return AplhaNum_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNNX0lhdKd7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "apha_num_list1 = list(map(str,alpha_num_list()))\n",
        "apha_num_list1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PXo794jbPKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultsss[ resultsss[1]== \"I\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc7hLXjODihL",
        "colab_type": "text"
      },
      "source": [
        "Test number of occurence and not in dataframe of elements in list (eg: aplhabets and numbers list)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxU0Ebh88kCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def num_of_occurence_in_df(df,list):\n",
        "  count = 0\n",
        "  for i in list:\n",
        "    shape1 = df[df[1] == i].shape\n",
        "    print(f'count of {i} is {shape1[0]}')\n",
        "    if (shape1[0]== 0 ):\n",
        "      print(\"alhabet is not present >> \",i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5PwRj6bCJSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_of_occurence_in_df(resultsss,apha_num_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsX8t1UOikqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha_and_nums_df = resultsss[(resultsss[2]>0.75) &(resultsss[2]>0) & (resultsss[1].isin(apha_num_list1)) ]\n",
        "print(alpha_and_nums_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqb1P_zbAaLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "os.mkdir(\"/content/clear_alpha_num_output\")\n",
        "for i in alpha_num_list():\n",
        "  os.mkdir(f'/content/clear_alpha_num_output/{i}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp82cfAjM-eC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/clear_alpha_num_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBmF0p9oBMd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_alph_num = np.asarray(alpha_and_nums_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAc6jiYOEFXN",
        "colab_type": "code",
        "outputId": "f9e82cf0-0bc8-4af2-f9b3-ecb0357be2ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "np_alph_num.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5826, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_5K35CKEYa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count=0\n",
        "for a in np_alph_num:\n",
        "  if(a[1] in (apha_num_list1)):\n",
        "    count+=1\n",
        "    shutil.copy(a[0],f'/content/clear_alpha_num_output/{a[1]}')\n",
        "    print(f'Copy {a[0]} to /content/clear_alpha_num_output/{a[1]} : {count}')\n",
        "    \n",
        "print(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vycLQAhGB72",
        "colab_type": "code",
        "outputId": "337b03dd-500b-4ebf-9e1e-8ac171981438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!ls -l -R /content/sorted | wc -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51dFt09HH3XP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r  \"/content/sorted.zip\" \"/content/sorted\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H49APgmRZBMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r '/content/clear_alpha_num_output' '/content/sorted'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUTaMo5_aGzl",
        "colab_type": "code",
        "outputId": "7453d18f-adc1-434b-a110-920c3b3da9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "df_75 = pd.DataFrame({'0': np_alph_num[:, 0], '1': np_alph_num[:, 1],'2': np_alph_num[:, 2]})\n",
        "df_75"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/output/0.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.9995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/output/3.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.9995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/output/4.jpg</td>\n",
              "      <td>A</td>\n",
              "      <td>0.9998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/output/7.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/output/9.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5821</th>\n",
              "      <td>/content/output/9921.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.9998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5822</th>\n",
              "      <td>/content/output/9922.jpg</td>\n",
              "      <td>6</td>\n",
              "      <td>0.9995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5823</th>\n",
              "      <td>/content/output/9923.jpg</td>\n",
              "      <td>V</td>\n",
              "      <td>0.9717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5824</th>\n",
              "      <td>/content/output/9924.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5825</th>\n",
              "      <td>/content/output/9925.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>0.9998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5826 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             0  1       2\n",
              "0        /content/output/0.jpg  2  0.9995\n",
              "1        /content/output/3.jpg  2  0.9995\n",
              "2        /content/output/4.jpg  A  0.9998\n",
              "3        /content/output/7.jpg  2   0.999\n",
              "4        /content/output/9.jpg  1  0.9069\n",
              "...                        ... ..     ...\n",
              "5821  /content/output/9921.jpg  2  0.9998\n",
              "5822  /content/output/9922.jpg  6  0.9995\n",
              "5823  /content/output/9923.jpg  V  0.9717\n",
              "5824  /content/output/9924.jpg  1  0.9969\n",
              "5825  /content/output/9925.jpg  4  0.9998\n",
              "\n",
              "[5826 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjkGkRS-a0OY",
        "colab_type": "code",
        "outputId": "98962b42-65ff-405c-8d2d-00e508cdd6f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "type(df_75)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNWw4V4ibphh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_75 = resultsss[(resultsss[2]>0.75) &(resultsss[2]>0) & (resultsss[1].isin(apha_num_list1)) ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ylLXLdecK7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_of_occurence_in_df(df_75,apha_num_list)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}